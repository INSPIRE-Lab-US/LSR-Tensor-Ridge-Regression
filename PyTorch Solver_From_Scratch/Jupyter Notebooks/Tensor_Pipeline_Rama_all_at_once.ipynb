{"cells":[{"cell_type":"markdown","metadata":{"id":"KzKHJMnbfVlm"},"source":["# Tensor Pipeline"]},{"cell_type":"markdown","metadata":{"id":"uGRufj_xfVlo"},"source":["## Setting Path"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('../Code Files')\n","sys.path.append('../Data')"]},{"cell_type":"markdown","metadata":{"id":"BMZmvyrBfVlq"},"source":["## Import Libraries"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["import datetime\n","import numpy as np\n","import dill\n","from KFoldCV_PyTorch import KFoldCV\n","from train_test_PyTorch import train_test\n","from DataGenerationB_PyTorch import *\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{"id":"RraGuUhGfVls"},"source":["## Import Data"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1712171307195,"user":{"displayName":"Lakshitha Ramanayake Mudiyanselage","userId":"09058794058790427589"},"user_tz":240},"id":"YUFTld9DfVls","outputId":"c7820ce2-d7a9-4ca1-86d4-8ea8b3fad406"},"outputs":[{"name":"stdout","output_type":"stream","text":["(5000, 32, 32)\n","(5000,)\n","(1000, 32, 32)\n","(1000,)\n","(32, 32)\n"]}],"source":["import pickle\n","pkl_file = \"../Data/Bounded_Var_Time_2024-03-31 20_19_12, intercept_5,n_train_5000, n_test_1000, tensor_dimensions_[32 32], tensor_mode_ranks_[4 4], separation_rank_2.pkl\"\n","file= open(pkl_file, 'rb')\n","data = pickle.load(file)\n","file.close()\n","\n","X_train_Full = data[0]\n","print(data[0].shape)\n","\n","Y_train_Full = data[1]\n","print(data[1].shape)\n","\n","X_test_Full = data[2]\n","print(data[2].shape)\n","\n","Y_test_Full = data[3]\n","print(data[3].shape)\n","\n","B_tensored = data[4]\n","print(data[4].shape)"]},{"cell_type":"markdown","metadata":{"id":"GbG33zwAfVls"},"source":["## Subset Data"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":131,"status":"ok","timestamp":1712171311486,"user":{"displayName":"Lakshitha Ramanayake Mudiyanselage","userId":"09058794058790427589"},"user_tz":240},"id":"wuhNbclbEkQT"},"outputs":[],"source":["n_train_all = [650]\n","n_test = 100\n","\n","tensor_dimensions = np.array([32, 32])\n","tensor_mode_ranks = np.array([4, 4])\n","separation_rank = 2\n"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y1zfvEkAfVlt","outputId":"ca512bba-2dc2-4330-a2e6-f1582720dfe9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of Samples: 650 ---------------------------------------------------------------------------------------------------------------------------\n","Sample mean for each feature (across samples): [-0.01644861  0.04633693  0.0153293  ... -0.016365    0.01499875\n"," -0.01838527]\n","Sample variance for each feature (across samples): None\n","Response Average: 4.4868813969566395\n"]},{"ename":"AttributeError","evalue":"'LSR_tensor_dot' object has no attribute 'device'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m k_folds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m     50\u001b[0m hypers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m200\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mranks\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tensor_mode_ranks), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseparation_rank\u001b[39m\u001b[38;5;124m'\u001b[39m: separation_rank}\n\u001b[1;32m---> 51\u001b[0m lambda1, validation_normalized_estimation_error, validation_nmse_losses, validation_correlations, validation_R2_scores, objective_function_information \u001b[38;5;241m=\u001b[39m \u001b[43mKFoldCV\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mB_tensored\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_folds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhypers\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_train_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m hypers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m200\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthreshold\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mranks\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mtuple\u001b[39m(tensor_mode_ranks), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseparation_rank\u001b[39m\u001b[38;5;124m'\u001b[39m: separation_rank}\n\u001b[0;32m     54\u001b[0m normalized_estimation_error, test_nmse_loss, test_R2_loss, test_correlation, objective_function_values \u001b[38;5;241m=\u001b[39m train_test(X_train, Y_train, X_test, Y_test, B_tensored, lambda1, hypers, Y_train_mean,intercept\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n","File \u001b[1;32md:\\Tensor Based ML for Neuro Imaging\\Tensor Coding Practice\\LSR-Tensor-Ridge-Regression\\PyTorch Solver\\Jupyter Notebooks\\../Code Files\\KFoldCV_PyTorch.py:24\u001b[0m, in \u001b[0;36mKFoldCV\u001b[1;34m(X_train, Y_train, B_tensored, alphas, k_folds, hypers, Y_train_mean)\u001b[0m\n\u001b[0;32m     21\u001b[0m LSR_tensor_dot_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape)[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Initialize LSR Tensors for each alpha iteration\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m lsr_tensors \u001b[38;5;241m=\u001b[39m [ [\u001b[43mLSR_tensor_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mLSR_tensor_dot_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparation_rank\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mseparation_rank\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m fold_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(k_folds)] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(alphas))]\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#Store objective function values for each fold/alpha\u001b[39;00m\n\u001b[0;32m     27\u001b[0m objective_function_information \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(shape \u001b[38;5;241m=\u001b[39m (k_folds, \u001b[38;5;28mlen\u001b[39m(alphas), hypers[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_iter\u001b[39m\u001b[38;5;124m'\u001b[39m], separation_rank, \u001b[38;5;28mlen\u001b[39m(ranks) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\n","File \u001b[1;32md:\\Tensor Based ML for Neuro Imaging\\Tensor Coding Practice\\LSR-Tensor-Ridge-Regression\\PyTorch Solver\\Jupyter Notebooks\\../Code Files\\LSR_Tensor_2D_v1_PyTorch.py:14\u001b[0m, in \u001b[0;36mLSR_tensor_dot.__init__\u001b[1;34m(self, shape, ranks, separation_rank, dtype, initialize, device)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39morder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(shape)\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialize\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32md:\\Tensor Based ML for Neuro Imaging\\Tensor Coding Practice\\LSR-Tensor-Ridge-Regression\\PyTorch Solver\\Jupyter Notebooks\\../Code Files\\LSR_Tensor_2D_v1_PyTorch.py:24\u001b[0m, in \u001b[0;36mLSR_tensor_dot.init_params\u001b[1;34m(self, initialize)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranks, device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;66;03m#self.core_tensor = np.random.normal(size = self.ranks)\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcore_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mparameter\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mnormal(mean\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,std\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,size\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mranks,device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Set up Factor Matrices\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m#self.factor_matrices = []\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfactor_matrices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModuleList()\n","\u001b[1;31mAttributeError\u001b[0m: 'LSR_tensor_dot' object has no attribute 'device'"]}],"source":["for i,n_train in enumerate(n_train_all):\n","  print('Number of Samples:',n_train,'---------------------------------------------------------------------------------------------------------------------------')\n","\n","  #Subset X_train and Y_train\n","  X_train = X_train_Full[0:(n_train),:,:]\n","  Y_train = Y_train_Full[0:(n_train)]\n","\n","  #Subset X_test and Y_test\n","  X_test = X_test_Full[0:(n_test),:,:]\n","  Y_test = Y_test_Full[0:(n_test)]\n","\n","  #Preprocessing\n","\n","  # Reshape the 3D array to a 2D array where each row represents a sample\n","  # The shape of the original 3D array is (n_samples, n_features_per_sample, n_dimensions)\n","  # We reshape it to (n_samples, n_features_per_sample * n_dimensions)\n","\n","\n","  X_train_2D = X_train.reshape(n_train, -1)\n","  X_test_2D = X_test.reshape(n_test,-1)\n","\n","\n","  # Initialize StandardScaler\n","  scaler = StandardScaler(with_std = False) #standard scalar only\n","\n","  # Fit scaler on train data and transform train data\n","  X_train_scaled = scaler.fit_transform(X_train_2D)\n","  # Transform test data using the scaler fitted on train data\n","  X_test_scaled = scaler.transform(X_test_2D)\n","\n","  # Reshape the scaled data back to 3D\n","  X_train = X_train_scaled.reshape(n_train, tensor_dimensions[0],tensor_dimensions[1])\n","  X_test  = X_test_scaled.reshape(n_test, tensor_dimensions[0],tensor_dimensions[1])\n","\n","  #average response value\n","  Y_train_mean = np.mean(Y_train)\n","  # Mean centering y_train and y_test\n","  Y_train = Y_train - Y_train_mean\n","\n","\n","  print(\"Sample mean for each feature (across samples):\",scaler.mean_)\n","  print(\"Sample variance for each feature (across samples):\",scaler.var_)\n","  print('Response Average:',Y_train_mean)\n","\n","  #For now, define finite alpha set that we are searching over\n","  alphas = [0,0.1,0.3, 0.5, 0.7, 0.9, 1, 1.5, 2, 2.5, 3, 5, 4,10,15,20,50,100]\n","\n","  #Define Number of Folds we want\n","  k_folds = 10\n","  hypers = {'max_iter': 200, 'threshold': 1e-4, 'ranks': tuple(tensor_mode_ranks), 'separation_rank': separation_rank}\n","  lambda1, validation_normalized_estimation_error, validation_nmse_losses, validation_correlations, validation_R2_scores, objective_function_information = KFoldCV(X_train, Y_train, B_tensored, alphas, k_folds, hypers,Y_train_mean)\n","\n","  hypers = {'max_iter': 200, 'threshold': 1e-4, 'ranks': tuple(tensor_mode_ranks), 'separation_rank': separation_rank}\n","  normalized_estimation_error, test_nmse_loss, test_R2_loss, test_correlation, objective_function_values = train_test(X_train, Y_train, X_test, Y_test, B_tensored, lambda1, hypers, Y_train_mean,intercept= False)\n","\n","  #Get current time and store in variable\n","  formatted_time = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n","  max_iter = hypers['max_iter']\n","  pkl_file = f\"/Users/lakrama/Neuro Project Codes/LSR-Tensor-Ridge-Regression/Closed_Form_Solver/Experimental Results/ExecutionTime_intercept_5_{formatted_time}, n_train_{n_train},n_test_{n_test}, tensor_dimensions:{tensor_dimensions}, tensor_mode_= ranks:{tensor_mode_ranks}, separation_rank:{separation_rank}, max_iter={max_iter}.pkl\"\n","\n","  print(\"Error Record on Training _ After K-Fold CV\")\n","  print(\"Validation Normalized Estimation Error: \", validation_normalized_estimation_error)\n","  print(\"Validation NMSE Losses: \", validation_nmse_losses)\n","  print(\"Validation Correlations: \", validation_correlations)\n","  print(\"Validation R2 Scores: \", validation_R2_scores)\n","\n","  print(\"Error Report on Testing _ With best Lambda\")\n","  print(\"Alpha chosen for model: \", lambda1)\n","  print(\"Test Normalized Estimation Error: \", normalized_estimation_error)\n","  print(\"Test NMSE Loss: \", test_nmse_loss)\n","  print(\"Test R2 Loss: \", test_R2_loss)\n","  print(\"Test Correlation: \", test_correlation)\n","\n","  with open(pkl_file, \"wb\") as file:\n","    dill.dump((X_train_Full, Y_train_Full, X_test_Full, Y_test_Full, B_tensored, lambda1, validation_normalized_estimation_error, validation_nmse_losses, validation_correlations, validation_R2_scores, objective_function_information, normalized_estimation_error, test_nmse_loss, test_R2_loss, test_correlation, objective_function_values), file)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzMXrkDVGKvU"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.2"}},"nbformat":4,"nbformat_minor":0}
